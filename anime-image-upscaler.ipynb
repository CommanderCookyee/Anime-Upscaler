{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Source: https://github.com/yu45020/Waifu2x","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.insert(1, \"/kaggle/input/repository/Waifu2x-master/\")\nfrom Models import *\nfrom utils import *","metadata":{"execution":{"iopub.status.busy":"2023-02-23T07:16:16.644678Z","iopub.execute_input":"2023-02-23T07:16:16.645086Z","iopub.status.idle":"2023-02-23T07:16:16.650769Z","shell.execute_reply.started":"2023-02-23T07:16:16.645053Z","shell.execute_reply":"2023-02-23T07:16:16.649578Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom utils.prepare_images import *\nfrom Models import *\nfrom torchvision.utils import save_image\n\n\nfrom torchvision.utils import save_image\nmodel_cran_v2 = CARN_V2(color_channels=3, mid_channels=64, conv=nn.Conv2d,\n                        single_conv_size=3, single_conv_group=1,\n                        scale=2, activation=nn.LeakyReLU(0.1),\n                        SEBlock=True, repeat_blocks=3, atrous=(1, 1, 1))\n                        \nmodel_cran_v2 = network_to_half(model_cran_v2)\ncheckpoint = \"/kaggle/input/repository/Waifu2x-master/model_check_points/CRAN_V2/CRAN_V2_02_28_2019/CARN_model_checkpoint.pt\"\nmodel_cran_v2.load_state_dict(torch.load(checkpoint, 'cpu'))\n# if use GPU, then comment out the next line so it can use fp16. \nmodel_cran_v2 = model_cran_v2.float() \n\ndemo_img = \"/kaggle/input/testimages/Drawn/camille-sule-wizardkingdoms-f.jpg\"\nimg = Image.open(demo_img).convert(\"RGB\")\n\n# origin\nimg_t = to_tensor(img).unsqueeze(0) \n\n# used to compare the origin\nimg = img.resize((img.size[0] // 2, img.size[1] // 2), Image.BICUBIC) \n\n# overlapping split\n# if input image is too large, then split it into overlapped patches \n# details can be found at [here](https://github.com/nagadomi/waifu2x/issues/238)\nimg_splitter = ImageSplitter(seg_size=64, scale_factor=2, boarder_pad_size=3)\nimg_patches = img_splitter.split_img_tensor(img, scale_method=None, img_pad=0)\nwith torch.no_grad():\n    out = [model_cran_v2(i) for i in img_patches]\nimg_upscale = img_splitter.merge_img_tensor(out)\n\nfinal = img_upscale\nsave_image(final, 'out1.png', nrow=1)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T07:33:45.478576Z","iopub.execute_input":"2023-02-23T07:33:45.478991Z","iopub.status.idle":"2023-02-23T07:34:49.090610Z","shell.execute_reply.started":"2023-02-23T07:33:45.478956Z","shell.execute_reply":"2023-02-23T07:34:49.089054Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n","output_type":"stream"}]}]}